{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "Ваша задача спарсить информацию о компаниях, находящихся в индексе S&P 500 с данного сайта: <br>\n",
    "https://markets.businessinsider.com/index/components/s&p_500\n",
    "\n",
    "Для каждой компании собрать следующую информацию:\n",
    "* Текущая стоимость в рублях (конвертацию производить по текущему курсу, взятому с сайта [центробанка РФ](http://www.cbr.ru/development/sxml/))\n",
    "* Код компании (справа от названия компании на странице компании)\n",
    "* P/E компании (информация находится справа от графика на странице компании)\n",
    "* Годовой рост/падение компании в процентах (основная таблица)\n",
    "* Высчитать какую прибыль принесли бы акции компании (в процентах), если бы они были куплены на уровне 52 Week Low и проданы на уровне 52 Week High (справа от графика на странице компании)\n",
    "\n",
    "Сохранить итоговую информацию в 4 JSON файла:\n",
    "1. Топ 10 компаний с самими дорогими акциями в рублях.\n",
    "2. Топ 10 компаний с самым низким показателем P/E.\n",
    "3. Топ 10 компаний, которые показали самый высокий рост за последний год\n",
    "4. Топ 10 комппаний, которые принесли бы наибольшую прибыль, если бы были куплены на самом минимуме и проданы на самом максимуме за последний год.\n",
    "<br>Пример формата:\n",
    "```\n",
    "[\n",
    "{\n",
    "    \"code\": \"MMM\",\n",
    "    \"name\": \"3M CO.\",\n",
    "    \"price\" | \"P/E\" | \"growth\" | \"potential profit\" : value,\n",
    "},\n",
    "...\n",
    "]\n",
    "```\n",
    "For scrapping you cans use `beautifulsoup4` <br>\n",
    "For requesting `aiohttp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВАЖНЫЙ КОММЕНТАРИЙ\n",
    "Range ограничен только первыми двумя страницами (всего их 10) для большего быстродействия во время демонстрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "class Company:\n",
    "    def __init__(self, name, ticker, price_rub, PE, year_stonks, year_result_percent):\n",
    "        self.name = name\n",
    "        self.ticker = ticker\n",
    "        self.price_rub = price_rub\n",
    "        self.PE = PE\n",
    "        self.year_stonks = year_stonks\n",
    "        self.year_result_percent = year_result_percent\n",
    "\n",
    "\n",
    "companies = []\n",
    "\n",
    "for i in range(2):\n",
    "    i += 1\n",
    "    url = f'https://markets.businessinsider.com/index/components/s&p_500?p={i}'\n",
    "    current_date = datetime.datetime.now()\n",
    "    formatted_date = current_date.strftime('%d/%m/%Y')\n",
    "    cb_url = f'https://www.cbr.ru/scripts/XML_daily.asp?date_req={formatted_date}'\n",
    "    cb_request = requests.get(cb_url)\n",
    "\n",
    "    # Парсинг XML\n",
    "    cb_xml = ET.fromstring(cb_request.text)\n",
    "\n",
    "    # Поиск элемента с USD\n",
    "    for valute in cb_xml.findall('Valute'):\n",
    "        char_code = valute.find('CharCode').text\n",
    "        if char_code == 'USD':\n",
    "            value = float(valute.find('Value').text.replace(',', '.'))\n",
    "\n",
    "    stonks_request = requests.get(url,headers=headers)\n",
    "\n",
    "    stonks_soup = BeautifulSoup(stonks_request.text,'html.parser')\n",
    "\n",
    "    companies_table = stonks_soup.find('tbody',class_='table__tbody')\n",
    "\n",
    "    # Проходимся по каждой строке\n",
    "    for tr in companies_table('tr'):\n",
    "        \n",
    "        if i == 1:\n",
    "            # Получаем каждую строку\n",
    "            tds = tr.find_all('td')\n",
    "            \n",
    "            # Достаём имя\n",
    "            a_tag = tds[0].find('a') \n",
    "            name = a_tag.get('title')\n",
    "\n",
    "            # Достаём цену в долларах\n",
    "            USD_price_raw = tds[1]\n",
    "            USD_price_str = USD_price_raw.get_text(strip=True, separator=' ')\n",
    "            first_number = USD_price_str.split()[0]\n",
    "            USD_price = float(first_number)\n",
    "            # Пересчитываем в рубли\n",
    "            RUB_price = round(USD_price*value,2)\n",
    "\n",
    "            # Достаём рост/падение за год из последнего столбца\n",
    "            year_result_span = tds[-1].find_all('span')\n",
    "            year_stonks = year_result_span[1].get_text()\n",
    "\n",
    "            # Достаём ссылку\n",
    "            link = a_tag.get('href')\n",
    "\n",
    "            # Переходим на страницу компании\n",
    "            company_request = requests.get(f'https://markets.businessinsider.com/{link}',headers=headers)\n",
    "            company_soup = BeautifulSoup(company_request.text,'html.parser')\n",
    "\n",
    "            # Достаём ticker\n",
    "            price_row = company_soup.find('h1', class_='price-section__identifiers')\n",
    "            price_span = price_row.find('span', class_='price-section__category')\n",
    "            mmm_span = price_span.find('span')\n",
    "            ticker = mmm_span.text[2:]\n",
    "\n",
    "            # Достаём P/E\n",
    "            snapshots = company_soup.find_all('div', class_='snapshot__data-item padding-right--zero')\n",
    "            # Переходим в нужный для нас snapshot \n",
    "            PE_snapshot = snapshots[14].get_text(strip = True)\n",
    "            PE_metric = PE_snapshot[:-9]\n",
    "\n",
    "            # Достаём 52 Week Low\n",
    "            snapshot_small = company_soup.find('div', class_='snapshot__data-item snapshot__data-item--small')\n",
    "            # Переходим в нужный для нас snapshot \n",
    "            year_week_low_snapshot = snapshot_small.get_text(strip = True)\n",
    "            year_week_low = year_week_low_snapshot[:-8]\n",
    "\n",
    "            # Достаём 52 Week High\n",
    "            snapshot_big = company_soup.find('div', class_='snapshot__data-item snapshot__data-item--small snapshot__data-item--right')\n",
    "            # Переходим в нужный для нас snapshot \n",
    "            year_week_high_snapshot = snapshot_big.get_text(strip = True)\n",
    "            year_week_high = year_week_high_snapshot[:-9]\n",
    "\n",
    "            # Считаем прибыль в процентах, округляя до двух знаков после запятой\n",
    "            year_result_percent = round((1 - (float(year_week_low)/float(year_week_high))) * 100,2)\n",
    "\n",
    "\n",
    "            # Сохраняем экземпляр класса\n",
    "            company_data = [\n",
    "                {'name':name,'price_rub':RUB_price,'ticker':ticker,'PE':PE_metric,'year_stonks':year_stonks,'YearResult':year_result_percent}\n",
    "            ]\n",
    "\n",
    "            companies_dict = {}\n",
    "\n",
    "            companies.append(Company(\n",
    "                name=name,\n",
    "                ticker=ticker,\n",
    "                price_rub=RUB_price,\n",
    "                PE=PE_metric,\n",
    "                year_stonks=year_stonks,\n",
    "                year_result_percent=year_result_percent))\n",
    "\n",
    "\n",
    "\n",
    "# Сортировки\n",
    "# 1. Топ-10 по цене\n",
    "top_price = sorted(companies, key=lambda x: x.price_rub, reverse=True)[:10]\n",
    "# 2. Топ-10 по P/E\n",
    "top_pe = sorted([c for c in companies if c.PE != float('inf')], key=lambda x: x.PE,reverse=True)[:10]\n",
    "# 3. Топ-10 по росту\n",
    "top_growth = sorted(companies, key=lambda x: x.year_stonks, reverse=True)[:10]\n",
    "# 4. Топ-10 по прибыли\n",
    "top_profit = sorted(companies, key=lambda x: x.year_result_percent, reverse=True)[:10]\n",
    "\n",
    "def create_json(data, key):\n",
    "    # Словарь для сопоставления ключей с атрибутами\n",
    "    attr_map = {\n",
    "        \"price\": \"price_rub\",\n",
    "        \"P/E\": \"PE\",\n",
    "        \"growth\": \"year_stonks\",\n",
    "        \"potential profit\": \"year_result_percent\"\n",
    "    }\n",
    "    return [\n",
    "        {\n",
    "            \"code\": item.ticker,\n",
    "            \"name\": item.name,\n",
    "            key: getattr(item, attr_map[key])\n",
    "        } for item in data\n",
    "    ]\n",
    "\n",
    "\n",
    "# Сохранение файлов\n",
    "with open('JSON\\\\top_price.json', 'w') as f:\n",
    "    json.dump(create_json(top_price, \"price\"), f, indent=2)\n",
    "\n",
    "with open('JSON\\\\top_pe.json', 'w') as f:\n",
    "    json.dump(create_json(top_pe, \"P/E\"), f, indent=2)\n",
    "\n",
    "with open('JSON\\\\top_growth.json', 'w') as f:\n",
    "    json.dump(create_json(top_growth, \"growth\"), f, indent=2)\n",
    "\n",
    "with open('JSON\\\\top_profit.json', 'w') as f:\n",
    "    json.dump(create_json(top_profit, \"potential profit\"), f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
